# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1igd9iEMva8euhuEEwJIzwIicayXzerNT
"""

import pandas as pd
import requests
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.tokenize import sent_tokenize
from bs4 import BeautifulSoup
import re
import nltk

nltk.download('punkt')
nltk.download("stopwords")

# Load stop words
with open('/content/StopWords_GenericLong.txt', 'r') as f:
    stop_words = f.read().split('\n')

# Load positive and negative word lists
positivewords = pd.read_excel(r'/content/positive-words.xlsx', header=None, names=['Word'])
positivewords = set(positivewords['Word'].str.lower())
negativewords = pd.read_excel(r'/content/negative-words.xlsx', header=None, names=['Word'])
negativewords = set(negativewords['Word'].str.lower())

# Function to calculate positive score
def get_positive_score(text):
    words = word_tokenize(text.lower())
    positive_words = [word for word in words if word in positivewords]
    return len(positive_words)

# Function to calculate negative score
def get_negative_score(text):
    words = word_tokenize(text.lower())
    negative_words = [word for word in words if word in negativewords]
    return len(negative_words)

# Function to calculate polarity score
def get_polarity_score(positive_score, negative_score):
    total_score = positive_score + negative_score
    return (positive_score - negative_score) / max(total_score, 1)

# Function to calculate subjectivity score
def get_subjectivity_score(positive_score, negative_score, word_count):
    total_score = positive_score + negative_score
    return total_score / max(word_count, 1)

# Function to calculate average sentence length
def get_avg_sentence_length(text):
    sentences = sent_tokenize(text)
    return sum(len(word_tokenize(sentence)) for sentence in sentences) / max(len(sentences), 1)

# Function to calculate percentage of complex words
def get_complex_word_percentage(text):
    words = word_tokenize(text)
    complex_words = [word for word in words if word.lower() not in stop_words and re.search(r'\b\w{6,}\b', word)]
    return (len(complex_words) / max(len(words), 1)) * 100

# Function to calculate Fog index
def get_fog_index(avg_sentence_length, complex_word_percentage):
    return 0.4 * (avg_sentence_length + complex_word_percentage)

# Function to process URL and calculate metrics
def process_url(url):
    response = requests.get(url)
    if response.status_code == 200:
        text = BeautifulSoup(response.text, 'html.parser').get_text()
        positive_score = get_positive_score(text)
        negative_score = get_negative_score(text)
        polarity_score = get_polarity_score(positive_score, negative_score)
        word_count = len(word_tokenize(text))
        avg_sentence_len = get_avg_sentence_length(text)
        complex_word_percentage = get_complex_word_percentage(text)
        fog_index = get_fog_index(avg_sentence_len, complex_word_percentage)
        return [positive_score, negative_score, polarity_score,
                get_subjectivity_score(positive_score, negative_score, word_count),
                avg_sentence_len, complex_word_percentage, fog_index, word_count]
    else:
        return [0] * 8  # Return zeros if URL cannot be fetched

# Read the DataFrame from Excel
df = pd.read_excel(r'/content/Input.xlsx')

# Apply processing to each URL in the DataFrame
df['Metrics'] = df['URL'].apply(process_url)

# Extract metrics into separate columns
df[['Positive Score', 'Negative Score', 'Polarity Score', 'Subjectivity Score',
    'Avg Sentence Length', 'Complex Word Percentage', 'Fog Index', 'Word Count']] = pd.DataFrame(df['Metrics'].tolist(), index=df.index)

# Drop the 'Metrics' column
df.drop(columns=['Metrics'], inplace=True)

# Print the DataFrame to see the output
print(df.head())

# Write the DataFrame to an Excel file
df.to_excel('output.xlsx', index=False)